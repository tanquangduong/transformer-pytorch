{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef737c9-b06c-4ffa-ad58-93ba4ee1fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\easyb\\Anaconda3\\envs\\transformer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer.utils import create_tranformer_model\n",
    "from transformer.utils import load_config, get_dataset, get_tokenizer\n",
    "from transformer.utils import get_checkpoint_path\n",
    "from transformer.engine import inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c37516-1db1-4a9a-8a88-ea2c0e050fc2",
   "metadata": {},
   "source": [
    "## Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde7a5a8-f2c3-45a5-a16d-e36bb117f780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Assign the device for computation (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "## Get Config, dataset, tokenizers\n",
    "config_file_path = \"./config.json\"\n",
    "config = load_config(config_file_path)\n",
    "dataset = get_dataset(config)\n",
    "tokenizer_src = get_tokenizer(config, dataset, config['language_source'])\n",
    "tokenizer_tgt = get_tokenizer(config, dataset, config['language_target'])\n",
    "\n",
    "## Define model, random input and get random output\n",
    "# Define the dimensions and vocabulary size\n",
    "# Define the parameters for the transformer model\n",
    "vocab_size_src = tokenizer_src.get_vocab_size()\n",
    "vocab_size_tgt = tokenizer_tgt.get_vocab_size()\n",
    "seq_len = config['seq_len']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ac50a-e336-431e-b95e-3b6ecfb82a52",
   "metadata": {},
   "source": [
    "## Load model and latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48feebf5-f0ce-49b9-b687-0642c0abe08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint: models\\transformer_15.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Transformer model\n",
    "model = create_tranformer_model(config, vocab_size_src, vocab_size_tgt).to(device)\n",
    "# Load latest checkpoint\n",
    "model_checkpoint = get_checkpoint_path(config)\n",
    "print(\"model_checkpoint:\", model_checkpoint)\n",
    "state = torch.load(model_checkpoint)\n",
    "# Assign latest checkpoint to transfromer\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bb83b-3720-4291-9392-30124e55bdcb",
   "metadata": {},
   "source": [
    "## Translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2c5a2f-6a33-42d3-aff9-307f03a94f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text: \n",
      " Market prices are shaped by the balance of supply and demand.\n",
      ">>>>\n",
      "Translated text: \n",
      " Les prix du marché sont façonnés par l ' équilibre de l ' offre et de la demande .\n"
     ]
    }
   ],
   "source": [
    "source_text = \"Market prices are shaped by the balance of supply and demand.\"\n",
    "translated_text = inference(source_text, \n",
    "                            model, \n",
    "                            tokenizer_src, \n",
    "                            tokenizer_tgt,\n",
    "                            seq_len,\n",
    "                            device)\n",
    "\n",
    "print(\"Source text: \\n\", source_text)\n",
    "print(\">>>>\")\n",
    "print(\"Translated text: \\n\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb04b9-e2bc-4231-b666-ee4ba7c6c328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
